{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c02ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b8a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=50, n_features=20, n_informative=2, noise=5, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7cfee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mse(y, y_pred):\n",
    "    return np.mean((y - y_pred) ** 2) \n",
    "\n",
    "def _mae(y, y_pred):\n",
    "    return np.mean(abs(y - y_pred))\n",
    "\n",
    "def _rmse(y, y_pred):\n",
    "    return np.sqrt(mse(y, y_pred))\n",
    "\n",
    "def _r2(y, y_pred):\n",
    "    mean_y = np.mean(y)\n",
    "    return 1 - np.sum((y-y_pred)**2)/np.sum((y-mean_y)**2)\n",
    "\n",
    "def _mape(y, y_pred):\n",
    "    return 100 * np.mean(abs((y-y_pred)/y))\n",
    "\n",
    "class MyLineReg:\n",
    "    def __init__(self, n_iter, learning_rate, metric = None, reg = None, l1_coef=0, l2_coef=0, random_state=42):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = None\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.random_state = random_state\n",
    "        self.scores = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "    \n",
    "    def l1(self):\n",
    "        return self.l1_coef * np.sign(self.weights) \n",
    "    \n",
    "    def l2(self):\n",
    "        return self.l2_coef * 2*self.weights\n",
    "    \n",
    "    def elasticnet(self):\n",
    "        return self.l1() + self.l2()\n",
    "\n",
    "    def fit(self, X, y, verbose=False):\n",
    "        random.seed(self.random_state)\n",
    "        n_samples, m_features = X.shape\n",
    "        \n",
    "        self.y = y\n",
    "        self.X = np.hstack((np.ones((n_samples, 1)), X))\n",
    "        self.weights = np.ones(m_features + 1)\n",
    "        \n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            y_pred = np.dot(self.X, self.weights)\n",
    "            \n",
    "            if self.metric != None: \n",
    "                loss_function = globals()[self.metric]\n",
    "                loss = loss_function(y, y_pred)\n",
    "                self.scores.append(loss)\n",
    "                \n",
    "            gradient = (2 / n_samples) * np.dot(self.X.T, (y_pred - y))\n",
    "            \n",
    "            if self.reg == 'l1':\n",
    "                gradient += self.l1()\n",
    "            elif self.reg == 'l2':\n",
    "                gradient += self.l2()\n",
    "            elif self.reg == 'elasticnet':\n",
    "                gradient += self.elasticnet()\n",
    "                \n",
    "            learning_rate = 0.1    \n",
    "            if callable(self.learning_rate):\n",
    "                learning_rate = self.learning_rate(i)\n",
    "            else: \n",
    "                learning_rate = self.learning_rate    \n",
    "                \n",
    "            self.weights -= learning_rate * gradient\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights)\n",
    "            \n",
    "    def get_coef(self):\n",
    "        return self.weights[1:]\n",
    "    \n",
    "    def get_best_score(self):\n",
    "        loss_function = globals()[self.metric]\n",
    "        y_pred = np.dot(self.X, self.weights)   \n",
    "        return loss_function(self.y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be113cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y):\n",
    "    n = len(y)\n",
    "    y_mean = y.mean()\n",
    "    return ((y-y_mean)**2).mean()\n",
    "\n",
    "def msep(y, X, Q):\n",
    "    n = len(y)\n",
    "    y_right = y.loc[X[X>Q].index]\n",
    "    y_left = y.loc[X[X<=Q].index]\n",
    "\n",
    "    mse_left = mse(y_left)\n",
    "    mse_right = mse(y_right)\n",
    "    \n",
    "    n_left = len(y_left)\n",
    "    n_right = len(y_right)\n",
    "    \n",
    "    return mse(y) - (n_left*mse_left/n + n_right*mse_right/n) \n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, split_column, split_value, predicted_classes):\n",
    "        self.split_column = split_column\n",
    "        self.split_value = split_value\n",
    "        self.predicted_classes = predicted_classes\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "class MyTreeReg:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, max_leafs=20, bins=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs if max_leafs > 1 else 2\n",
    "        self.bins = bins\n",
    "        self.fi = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"MyTreeClf class: max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}\"\n",
    "    \n",
    "    def fit(self,X, y):\n",
    "        self.n = len(y)\n",
    "        self.leafs_cnt = 1\n",
    "        self.fi = {key: 0 for key in X.columns}\n",
    "        if self.bins != None and self.bins < X.shape[0] - 2:\n",
    "            self.bins = self.get_bins(X)\n",
    "        else:\n",
    "            self.bins = None\n",
    "        self.node = self.build_tree(X, y,0)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        self.y_predict = pd.Series(index=X.index)\n",
    "        self.prediction(self.node, X)\n",
    "        return self.y_predict\n",
    "    \n",
    "    def get_bins(self, X):\n",
    "        bins = pd.DataFrame()\n",
    "        for column in X.columns:\n",
    "            sample = np.histogram(X[column], bins=self.bins)[1][1:-1]\n",
    "            bins[column] = sample    \n",
    "        return bins\n",
    "    \n",
    "    def prediction(self, node, X):\n",
    "        if type(node) == np.float64:\n",
    "            self.y_predict[X.index] = node\n",
    "            return\n",
    "        \n",
    "        left_indexes = X[node.split_column] <= node.split_value\n",
    "        right_indexes = X[node.split_column] > node.split_value\n",
    "        self.prediction(node.left, X[left_indexes])\n",
    "        self.prediction(node.right, X[right_indexes])     \n",
    "        \n",
    "    def build_tree(self, X, y, current_depth):\n",
    "        if self.leafs_cnt >= self.max_leafs:\n",
    "            return self.build_leaf(X,y)\n",
    "        \n",
    "        if X.shape[0] <= 1 or len(np.unique(y)) <= 1:\n",
    "            return self.build_leaf(X,y)\n",
    "        \n",
    "        split_column, Q, ig = self.get_best_split(X, y)\n",
    "        node = TreeNode(split_column, Q, -1)\n",
    "        \n",
    "        \n",
    "        if current_depth < self.max_depth and len(y) >= self.min_samples_split:\n",
    "\n",
    "            left_indices = X[split_column] <= Q\n",
    "            right_indices = X[split_column] > Q\n",
    "\n",
    "            X_left = X[left_indices]\n",
    "            y_left = y[left_indices]\n",
    "            X_right = X[right_indices]\n",
    "            y_right = y[right_indices]\n",
    "    \n",
    "            self.leafs_cnt += 1\n",
    "            node.left = self.build_tree(X_left, y_left, current_depth + 1)\n",
    "            node.right = self.build_tree(X_right, y_right, current_depth + 1)\n",
    "            \n",
    "            self.fi[split_column] += X.shape[0]/self.n*(\n",
    "                mse(y) - \n",
    "                len(y_left)/len(y)*mse(y_left) -\n",
    "                len(y_right)/len(y)*mse(y_right)\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            return self.build_leaf(X,y)\n",
    "        return node\n",
    "    \n",
    "    def build_leaf(self, X, y):\n",
    "        return np.sum(y[X.index]) / len(y[X.index])        \n",
    "    \n",
    "    def get_best_split(self, X, y):\n",
    "        best_ig = 0\n",
    "        best_Q = 0\n",
    "        best_column_name = None\n",
    "        prev_value = None\n",
    "       \n",
    "        if self.bins is None:\n",
    "            for column in X.columns:\n",
    "                column = X[column].sort_values()\n",
    "                for index, value in column.items():\n",
    "                    if prev_value != None:\n",
    "                        Q = (prev_value + value)/2\n",
    "                        ig = msep(y, column, Q)\n",
    "                        if ig > best_ig:\n",
    "                            best_ig = ig\n",
    "                            best_Q = Q\n",
    "                            best_column_name = column.name\n",
    "                    prev_value = value\n",
    "        else:\n",
    "            for column in X.columns:\n",
    "                sample = self.bins[column]\n",
    "                column = X[column]\n",
    "                for Q in sample:\n",
    "                    ig = msep(y, column, Q)\n",
    "                    if ig > best_ig:\n",
    "                        best_ig = ig\n",
    "                        best_Q = Q\n",
    "                        best_column_name = column.name\n",
    "          \n",
    "        return best_column_name, best_Q, best_ig  \n",
    "    \n",
    "    def print_tree(self, node):\n",
    "        if type(node) == np.float64:\n",
    "            print(node)\n",
    "            return\n",
    "        print(node.split_column, node.split_value)\n",
    "        self.print_tree(node.left)\n",
    "        self.print_tree(node.right)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40563ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyForestReg:\n",
    "    \n",
    "    def __init__(self, n_estimators=10, max_features=0.5, max_samples=0.5,\n",
    "                 max_depth=5, min_samples_split=2, max_leafs=20, bins=16, random_state=42, oob_score=None):\n",
    "            \n",
    "        self.n_estimators = n_estimators    \n",
    "        self.max_features = max_features\n",
    "        self.max_samples = max_samples\n",
    "        self.random_state = random_state\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs if max_leafs > 1 else 2\n",
    "        self.bins = bins\n",
    "        self.fi = None\n",
    "        self.forest = []\n",
    "        self.leafs_cnt = 0\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"MyForestReg class: n_estimators={self.n_estimators}, max_features={self.max_features},\" + f\"max_samples={self.max_samples}, max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}, bins={self.bins}, random_state={self.random_state}\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        random.seed(self.random_state)\n",
    "        init_cols = X.columns.tolist()\n",
    "        init_rows_cnt = X.shape[0]\n",
    "        \n",
    "        cols_smpl_cnt = int(np.round(len(X.columns) * self.max_features))\n",
    "        rows_smpl_cnt = int(np.round(X.shape[0] * self.max_samples))\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            cols_idx = random.sample(init_cols, cols_smpl_cnt)\n",
    "            rows_idx = random.sample(range(init_rows_cnt), rows_smpl_cnt)\n",
    "            \n",
    "            forest_tree = MyTreeReg(max_depth=self.max_depth, min_samples_split=self.min_samples_split,\n",
    "                                   max_leafs=self.max_leafs, bins=self.bins)\n",
    "            forest_tree.fit(X.loc[rows_idx, cols_idx], y[rows_idx])\n",
    "            \n",
    "            oob_rows_idx = X.index.difference(rows_idx)\n",
    "            \n",
    "            y_prediction = forest_tree.predict(X.loc[oob_rows_idx, cols_idx])\n",
    "            self.oob_score_ += self.oob_score(y[oob_rows_idx], y_prediction)\n",
    "            \n",
    "            self.leafs_cnt += forest_tree.leafs_cnt\n",
    "            \n",
    "            self.forest.append(forest_tree)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        y_prediction = np.zeros(X.shape[0])\n",
    "        for forest_tree in self.forest:\n",
    "            y_prediction += forest_tree.predict(X)\n",
    "        return y_prediction/X.shape[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a3ab47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a458c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBaggingReg:\n",
    "    def __init__(self, estimator=None, n_estimators=10, max_samples=1.0, random_state=42):\n",
    "        self.estimator = estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.random_state = random_state\n",
    "        self.estimators = []\n",
    "       \n",
    "    def __str__(self):\n",
    "        return f\"MyBaggingReg class: estimator={self.estimator}, n_estimators={self.n_estimators}, max_samples={self.max_samples}, random_state={self.random_state}\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        random.seed(self.random_state)\n",
    "        rows_smpl_cnt = int(np.round(X.shape[0] * self.max_samples))\n",
    "        for i in range(self.n_estimators):\n",
    "            estimator = copy.deepcopy(self.estimator)\n",
    "            sample_rows_idx = random.choices(X.index, k=rows_smpl_cnt)\n",
    "            estimator.fit(X.iloc[sample_rows_idx], y[sample_rows_idx])\n",
    "            self.estimators.append(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03757d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyBaggingReg(estimator=MyLineReg(n_iter=10, learning_rate=0.1)).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5e5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500eef0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
