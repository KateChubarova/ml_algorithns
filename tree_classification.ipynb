{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cddfdb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd962e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=200, n_features=20, n_informative=2, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ed7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad7b694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    return np.sum((y_true == 1) & (y_pred == 1)) \n",
    "\n",
    "def false_negative(y_true, y_pred):\n",
    "    return np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "def false_positive(y_true, y_pred):\n",
    "    return np.sum((y_true == 0) & (y_pred == 1))\n",
    "\n",
    "def true_negative(y_true, y_pred):\n",
    "    return np.sum((y_true == 0) & (y_pred == 0))\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    return (tp + tn)/len(y_true)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    return tp/(tp+fp)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    return tp/(tp+fn)\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precision_value = precision(y_true, y_pred)\n",
    "    recall_value = recall(y_true, y_pred)\n",
    "    return (2*precision_value*recall_value)/(precision_value + recall_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db0930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y): #энтропия\n",
    "    entropy = 0\n",
    "    classes = y.unique()\n",
    "    for i in classes:\n",
    "        count = (y==i).sum()\n",
    "        p = count/len(y)\n",
    "        entropy += p*np.log2(eps+p)\n",
    "    return -entropy              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eee7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IG(y, X, Q): #прирост информации \n",
    "    n = len(y)\n",
    "    y1 = y.loc[X[X>Q].index]\n",
    "    y2 = y.loc[X[X<=Q].index]\n",
    "\n",
    "    S1 = entropy(y1)\n",
    "    S2 = entropy(y2)\n",
    "    \n",
    "    S0 = entropy(y)\n",
    "    return S0 - (S1*len(y1)/n + S2*len(y2)/n)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c650fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y): #джинни\n",
    "    gini = 0\n",
    "    classes = y.unique()\n",
    "    for i in classes:\n",
    "        count = (y==i).sum()\n",
    "        p = count/len(y)\n",
    "        gini += p**2    \n",
    "    return 1 - gini    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9a59168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_gain(y, X, Q): #джинни гейн\n",
    "\n",
    "    y1 = y.loc[X[X > Q].index]\n",
    "    y2 = y.loc[X[X <= Q].index]\n",
    "    \n",
    "    G1 = G(y1)\n",
    "    G2 = G(y2)\n",
    "    \n",
    " \n",
    "    n1 = len(y1)\n",
    "    n2 = len(y2)\n",
    "    \n",
    "    return G(y) - (G1*n1 + G2*n2)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa76295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_banknote_authentication.txt', header=None)\n",
    "df.columns = ['variance', 'skewness', 'curtosis', 'entropy', 'target']\n",
    "X, y = df.iloc[:,:4], df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfb4e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, split_column, split_value, predicted_classes):\n",
    "        self.split_column = split_column\n",
    "        self.split_value = split_value\n",
    "        self.predicted_classes = predicted_classes\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "604870e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTreeClf:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, max_leafs=20, bins=None, criterion='entropy'):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs if max_leafs > 1 else 2\n",
    "        self.leafs_cnt = 0\n",
    "        self.bins = bins\n",
    "        if criterion == 'gini':\n",
    "            self.criterion = globals()['gini_gain']\n",
    "        else:\n",
    "            self.criterion = globals()['IG']\n",
    "        self.metric = globals()[criterion]    \n",
    "        self.fi = {}\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"MyTreeClf class: max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}\"\n",
    "    \n",
    "    \n",
    "    def get_best_split(self, X, y):\n",
    "        best_ig = 0\n",
    "        best_Q = 0\n",
    "        best_column_name = None\n",
    "        prev_value = None\n",
    "       \n",
    "        if self.bins is None:\n",
    "            for column in X.columns:\n",
    "                column = X[column].sort_values()\n",
    "                for index, value in column.items():\n",
    "                    if prev_value != None:\n",
    "                        Q = (prev_value + value)/2\n",
    "                        ig = self.criterion(y, column, Q)\n",
    "                        if ig > best_ig:\n",
    "                            best_ig = ig\n",
    "                            best_Q = Q\n",
    "                            best_column_name = column.name\n",
    "                    prev_value = value \n",
    "        else:\n",
    "            for column in X.columns:\n",
    "                sample = self.bins[column]\n",
    "                column = X[column]\n",
    "                for Q in sample:\n",
    "                    ig = self.criterion(y, column, Q)\n",
    "                    if ig > best_ig:\n",
    "                        best_ig = ig\n",
    "                        best_Q = Q\n",
    "                        best_column_name = column.name\n",
    "          \n",
    "        return best_column_name, best_Q, best_ig    \n",
    "    \n",
    "    \n",
    "    def build_leaf(self, X, y):\n",
    "        return np.sum(y[X.index]) / len(y[X.index])\n",
    "    \n",
    "    def build_tree(self, X, y, current_depth):\n",
    "        if self.leafs_cnt >= self.max_leafs:\n",
    "            return self.build_leaf(X,y)\n",
    "        \n",
    "        if X.shape[0] <= 1 or len(np.unique(y)) <= 1:\n",
    "            return self.build_leaf(X,y)\n",
    "        \n",
    "        split_column, Q, ig = self.get_best_split(X, y)\n",
    "        node = TreeNode(split_column, Q, -1)\n",
    "        \n",
    "        \n",
    "        if current_depth < self.max_depth and len(y) >= self.min_samples_split:\n",
    "\n",
    "            left_indices = X[split_column] <= Q\n",
    "            right_indices = X[split_column] > Q\n",
    "\n",
    "            X_left = X[left_indices]\n",
    "            y_left = y[left_indices]\n",
    "            X_right = X[right_indices]\n",
    "            y_right = y[right_indices]\n",
    "    \n",
    "            self.leafs_cnt += 1\n",
    "            node.left = self.build_tree(X_left, y_left, current_depth + 1)\n",
    "            node.right = self.build_tree(X_right, y_right, current_depth + 1)\n",
    "            \n",
    "            self.fi[split_column] += X.shape[0]/self.n*(\n",
    "                self.metric(y) - \n",
    "                len(y_left)/len(y)*self.metric(y_left) -\n",
    "                len(y_right)/len(y)*self.metric(y_right)\n",
    "            )\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            return self.build_leaf(X,y)\n",
    "        return node\n",
    "        \n",
    "    def fit(self,X, y):\n",
    "        self.n = len(y)\n",
    "        self.leafs_cnt = 1\n",
    "        self.fi = {key: 0 for key in X.columns}\n",
    "        if self.bins != None and self.bins < X.shape[0] - 2:\n",
    "            self.bins = self.get_bins(X)\n",
    "        else:\n",
    "            self.bins = None\n",
    "        self.node = self.build_tree(X, y,0)\n",
    "        \n",
    "    def get_bins(self, X):\n",
    "        bins = pd.DataFrame()\n",
    "        for column in X.columns:\n",
    "            sample = np.histogram(X[column], bins=self.bins)[1][1:-1]\n",
    "            bins[column] = sample    \n",
    "        return bins\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y = self.predict_proba(X)\n",
    "        return y.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "            \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        self.y_predict = pd.Series(index=X.index)\n",
    "        self.prediction(self.node, X)\n",
    "        return self.y_predict\n",
    "    \n",
    "    def prediction(self, node, X):\n",
    "        if type(node) == np.float64:\n",
    "            self.y_predict[X.index] = node\n",
    "            return\n",
    "        \n",
    "        left_indexes = X[node.split_column] <= node.split_value\n",
    "        right_indexes = X[node.split_column] > node.split_value\n",
    "        self.prediction(node.left, X[left_indexes])\n",
    "        self.prediction(node.right, X[right_indexes]) \n",
    "            \n",
    "    def print_tree(self, node):\n",
    "        if type(node) == np.float64:\n",
    "            print(node)\n",
    "            return\n",
    "        print(node.split_column, node.split_value)\n",
    "        self.print_tree(node.left)\n",
    "        self.print_tree(node.right)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a8b85411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyForestClf:\n",
    "    \n",
    "    def __init__(self, n_estimators=10, max_features=0.5, max_samples=0.5, random_state=42,\n",
    "                 max_depth=5, min_samples_split=2, max_leafs=20, bins=16, criterion='entropy', oob_score=None):\n",
    "        self.n_estimators = n_estimators    \n",
    "        self.max_features = max_features\n",
    "        self.max_samples = max_samples\n",
    "        self.random_state = random_state\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs if max_leafs > 1 else 2\n",
    "        self.bins = bins\n",
    "        self.criterion = criterion\n",
    "        self.leafs_cnt = 0\n",
    "        self.forest = []\n",
    "#         self.fi = None\n",
    "        self.oob_score_ = 0\n",
    "        if oob_score is not None:\n",
    "            self.oob_score = globals()[oob_score]\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"MyForestClf class: n_estimators={self.n_estimators}, max_features={self.max_features},\" + f\"max_samples={self.max_samples}, max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}, bins={self.bins}, criterion={self.criterion}, random_state={self.random_state}\"\n",
    "       \n",
    "    def fit(self, X, y):\n",
    "        random.seed(self.random_state)\n",
    "        init_cols = X.columns.tolist()\n",
    "        init_rows_cnt = X.shape[0]\n",
    "#         self.fi = {key: 0 for key in X.columns}\n",
    "        \n",
    "        cols_smpl_cnt = int(np.round(len(X.columns) * self.max_features))\n",
    "        rows_smpl_cnt = int(np.round(X.shape[0] * self.max_samples))\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            cols_idx = random.sample(init_cols, cols_smpl_cnt)\n",
    "            rows_idx = random.sample(range(init_rows_cnt), rows_smpl_cnt)\n",
    "            \n",
    "            forest_tree = MyTreeClf(max_depth=self.max_depth, min_samples_split=self.min_samples_split,\n",
    "                                   max_leafs=self.max_leafs, bins=self.bins, criterion=self.criterion)\n",
    "            forest_tree.fit(X.loc[rows_idx, cols_idx], y[rows_idx])\n",
    "            \n",
    "            oob_rows_idx = X.index.difference(rows_idx)\n",
    "            y_prediction = forest_tree.predict(X.loc[oob_rows_idx, cols_idx])\n",
    "            if self.oob_score is not None:\n",
    "                self.oob_score_ += self.oob_score(y[oob_rows_idx], y_prediction)\n",
    "            \n",
    "            self.leafs_cnt += forest_tree.leafs_cnt\n",
    "#             for key in forest_tree.fi:\n",
    "#                 self.fi[key] += forest_tree.fi[key]\n",
    "            \n",
    "            self.forest.append(forest_tree)\n",
    "        if self.oob_score is not None:\n",
    "            self.oob_score_ = self.oob_score_ / len(self.forest)\n",
    "            \n",
    "    def predict(self, X, type):\n",
    "        y_prediction = np.zeros(X.shape[0])\n",
    "        if type == 'mean':\n",
    "            for forest_tree in self.forest:\n",
    "                y_prediction += forest_tree.predict_proba(X)\n",
    "            return (y_prediction/len(self.forest)).apply(lambda x: 1 if x > 0.5 else 0)  \n",
    "        elif type == 'vote':\n",
    "            for forest_tree in self.forest:\n",
    "                y_prediction += forest_tree.predict(X)\n",
    "            return (y_prediction/len(self.forest)).apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        y_prediction = np.zeros(X.shape[0])\n",
    "        for forest_tree in self.forest:\n",
    "            y_prediction += forest_tree.predict_proba(X)\n",
    "        return y_prediction/len(self.forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cfc559bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = MyForestClf(n_estimators=6, max_depth=2, max_features=0.6, max_samples=0.5, criterion='entropy', oob_score='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4d2f11c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d2456db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.leafs_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3f98ab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "1367    1\n",
       "1368    1\n",
       "1369    1\n",
       "1370    1\n",
       "1371    1\n",
       "Length: 1372, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.predict(X, type='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dfc95b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253524836599691"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.oob_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
